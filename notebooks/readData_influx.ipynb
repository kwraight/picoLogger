{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.exceptions import InfluxDBError\n",
    "from getpass import getpass\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from connectionDetails import GetInfluxCredentials  # Import the function\n",
    "from urllib3 import exceptions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set influx connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List installed package versions\n",
    "packList = [\"pandas\", \"altair\", \"numpy\", \"itkdb\"]\n",
    "for p in packList:\n",
    "    try:\n",
    "        mod = __import__(p)\n",
    "        print(mod.__name__ + \" : \" + mod.__version__)\n",
    "    except ImportError:\n",
    "        print(p + \" not installed\")\n",
    "\n",
    "# Get the current working directory\n",
    "thisDir = os.getcwd()\n",
    "\n",
    "# List files in the parent directory\n",
    "parentDir = os.path.abspath(os.path.join(thisDir, os.pardir))\n",
    "files_in_parent = os.listdir(parentDir)\n",
    "print(\"Files in parent directory:\", files_in_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data\n",
    "\n",
    "The code below takes in the flux data as well as the data from the picolog folder to perform calculations on them and produce an output in the csv file 'output_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp converter function\n",
    "def TimeStampConverter(inStr, inPat):\n",
    "    timeObj = None\n",
    "    if inStr == \"now\":\n",
    "        timeObj = datetime.now()\n",
    "    else:\n",
    "        timeObj = datetime.strptime(inStr, inPat)\n",
    "    return timeObj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### geting temp., humid. data from influx\n",
    "def fetch_temperature_and_humidity(start_time_str, bucket_remote, url_remote, token_remote, org_remote):\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)\n",
    "    query_api_remote = clientV2_remote.query_api()\n",
    "\n",
    "    start_time = datetime.strptime(str(start_time_str), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    filters = {'_measurement': \"data\"}\n",
    "    query_str = f'from(bucket: \\\"{bucket_remote}\\\") |> range(start: {start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")})'\n",
    "    for k, v in filters.items():\n",
    "        query_str += f' |> filter(fn: (r) => r[\"{k}\"] == \"{v}\")'\n",
    "    query_str += ' |> yield(name: \"mean\")'\n",
    "\n",
    "    try:\n",
    "        query_result_remote = query_api_remote.query_data_frame(org=org_remote, query=query_str)\n",
    "        print(\"Connection with query API successful :)\")\n",
    "\n",
    "        temperature_results = []\n",
    "        humidity_results = []\n",
    "        for index, row in query_result_remote.iterrows():\n",
    "            if row['_field'] == 'temperature':\n",
    "                temperature_results.append(row.to_dict())\n",
    "            elif row['_field'] == 'humidity':\n",
    "                humidity_results.append(row.to_dict())\n",
    "\n",
    "        if len(temperature_results) > 0:\n",
    "            temperature = temperature_results[0]['_value']\n",
    "        else:\n",
    "            temperature = None\n",
    "\n",
    "        if len(humidity_results) > 0:\n",
    "            humidity = humidity_results[0]['_value']\n",
    "        else:\n",
    "            humidity = None\n",
    "\n",
    "    except (ConnectionError, TimeoutError):\n",
    "        print(\"Connection Error with query API\")\n",
    "        temperature, humidity = None, None\n",
    "    except Exception as e:\n",
    "        print(\"issue with query:\")\n",
    "        print(e)\n",
    "        print(e.__module__)\n",
    "        temperature, humidity = None, None\n",
    "    \n",
    "    print(f\"\\treturning T: {temperature}, RH: {humidity}\")\n",
    "\n",
    "    return temperature, humidity\n",
    "\n",
    "    return temperature, humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform calculations function\n",
    "\n",
    "### useful details\n",
    "\n",
    "def perform_calculations(input_folder, output_file, credentials, timestamp_str):\n",
    "    # Extract credentials\n",
    "    bucket_remote = credentials['bucket']\n",
    "    org_remote = credentials['org']\n",
    "    token_remote = credentials['token']\n",
    "    url_remote = credentials['url']\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    timestamp = TimeStampConverter(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "    \n",
    "     # Initialize the InfluxDB client with the extracted host and port\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)\n",
    "\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "            # Calculate Vin Drop and GND Drop\n",
    "            data['Vin Drop (V)'] = data['Vin+ Last (V)'] - data['Vin- Last (V)']\n",
    "            data['GND Drop (V)'] = data['GND+ Last (V)'] - data['GND- Last (V)']\n",
    "            \n",
    "            # Calculate Resistance Vin(Ohms) and Total Resistance(mOhms)\n",
    "            data['Resistance Vin(Ohms)'] = data['Vin Drop (V)'] / 10 / 5\n",
    "            data['Resistance GND(Ohms)'] = data['GND Drop (V)'] / 10 / 5\n",
    "            data['Total Resistance(mOhms)'] = (data['Resistance Vin(Ohms)'] + data['Resistance GND(Ohms)']) * 1000\n",
    "            \n",
    "            # Calculate Capacitor Equivalent leakage current(nA)\n",
    "            data['Capacitor Equivalent leakage current(nA)'] = ((data['Capacitor leakage test Last (V)'] / 10) / (1 * 10 ** 6)) / 1000000\n",
    "            \n",
    "            # Calculate NTC value(Kohms)\n",
    "            data['NTC value (Kohms)'] = 0.2 * 51 / data['NTC Last (V)']\n",
    "            \n",
    "            # Fetch temperature and humidity\n",
    "            temperature, humidity = fetch_temperature_and_humidity(timestamp_str, bucket_remote, url_remote, token_remote, org_remote)\n",
    "            \n",
    "            # Prepare the new DataFrame with desired columns and values\n",
    "            result_data = pd.DataFrame({\n",
    "                'component': filename,\n",
    "                'componentType': 'PCB',\n",
    "                'stage': 'PCB_QC',\n",
    "                'testType': 'HV_LV_TEST',\n",
    "                'institution': 'Glasgow',\n",
    "                'runNumber': data.shape[0],\n",
    "                'date': date.today().strftime('%Y-%m-%d'),\n",
    "                'passed': 'true',\n",
    "                'problems': 'false',\n",
    "                'property1_value': 'B.masic',\n",
    "                'property1_key': 'OPERATOR',\n",
    "                'property2_value': 'INSTRUMENT',\n",
    "                'property2_key': '',\n",
    "                'property3_value': 'ANALYSIS_VERSION',\n",
    "                'property3_key': '',\n",
    "                'result1_key': 'VIN_DROP',\n",
    "                'result1_value': data['Vin Drop (V)'],\n",
    "                'result2_key': 'GND_DROP',\n",
    "                'result2_value': data['GND Drop (V)'],\n",
    "                'result3_key': 'EFFECTIVE RESISTANCE',\n",
    "                'result3_value': data['Total Resistance(mOhms)'],\n",
    "                'result4_key': 'HV_LEAKAGE',\n",
    "                'result4_value': data['Capacitor leakage test Last (V)'],\n",
    "                'result5_key': 'LEAKAGE_CURRENT (nA)',\n",
    "                'result5_value': data['Capacitor Equivalent leakage current(nA)'],\n",
    "                'result6_key': 'NTC_VOLTAGE',\n",
    "                'result6_value': data['NTC Last (V)'],\n",
    "                'result7_key': 'NTC_VALUE',\n",
    "                'result7_value': data['NTC value (Kohms)'],\n",
    "                'result8_key': 'TERMPERATURE',\n",
    "                'result8_value': temperature,\n",
    "                'result9_key': 'DAMAGE_COMMENT',\n",
    "                'result9_value': '',\n",
    "                'result10_key': 'R1_HV_RESISTOR',\n",
    "                'result10_value': '',\n",
    "                'result11_key': 'RELATIVE_HUMIDITY',\n",
    "                'result11_value': humidity,\n",
    "                'timestamp': timestamp  # Add the timestamp column to the DataFrame\n",
    "            })\n",
    "            \n",
    "            all_data.append(result_data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_result = pd.concat(all_data, ignore_index=True)\n",
    "        final_result.to_csv(output_file, index=False)\n",
    "        print(f\"Calculation completed. Output saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run calculations\n",
    "input_folder = os.path.join(parentDir, \"picolog_folder\")\n",
    "output_file = os.path.join(parentDir, \"output_file.csv\")\n",
    "timestamp_str = \"2023-08-08 14:30:00\"\n",
    "\n",
    "influx_credentials = GetInfluxCredentials()\n",
    "print(influx_credentials)\n",
    "\n",
    "perform_calculations(input_folder, output_file, influx_credentials, timestamp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
