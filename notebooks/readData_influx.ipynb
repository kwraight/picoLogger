{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.exceptions import InfluxDBError\n",
    "from getpass import getpass\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set influx connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas : 1.4.4\n",
      "altair : 5.0.1\n",
      "numpy : 1.21.5\n",
      "itkdb not installed\n",
      "Files in parent directory: ['.git', '.gitignore', '.ipynb_checkpoints', 'notebooks', 'output_file.csv', 'picolog_folder', 'README.md', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "# List installed package versions\n",
    "packList = [\"pandas\", \"altair\", \"numpy\", \"itkdb\"]\n",
    "for p in packList:\n",
    "    try:\n",
    "        mod = __import__(p)\n",
    "        print(mod.__name__ + \" : \" + mod.__version__)\n",
    "    except ImportError:\n",
    "        print(p + \" not installed\")\n",
    "\n",
    "# Get the current working directory\n",
    "thisDir = os.getcwd()\n",
    "\n",
    "# List files in the parent directory\n",
    "parentDir = os.path.abspath(os.path.join(thisDir, os.pardir))\n",
    "files_in_parent = os.listdir(parentDir)\n",
    "print(\"Files in parent directory:\", files_in_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection details:\n",
      "bucket_remote: GLADD\n",
      "org_remote: PPE\n",
      "token_remote: EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ==\n",
      "url_remote: 194.36.1.20:8086\n"
     ]
    }
   ],
   "source": [
    "# Set original credentials\n",
    "bucket_remote = \"GLADD\"\n",
    "org_remote = \"PPE\"\n",
    "token_remote = \"EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ==\"\n",
    "url_remote = \"194.36.1.20:8086\"\n",
    "\n",
    "print(\"Connection details:\")\n",
    "print(f\"bucket_remote: {bucket_remote}\")\n",
    "print(f\"org_remote: {org_remote}\")\n",
    "print(f\"token_remote: {token_remote}\")\n",
    "print(f\"url_remote: {url_remote}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetInfluxCredentials():\n",
    "    print(\"Getting Influx info.\")\n",
    "    return {\n",
    "        'bucket': \"GLADD\",\n",
    "        'org': \"PPE\",\n",
    "        'token': \"EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ==\",\n",
    "        'url': \"194.36.1.20\",\n",
    "        'port': \"8086\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data\n",
    "\n",
    "The code below takes in the flux data as well as the data from the picolog folder to perform calculations on them and produce an output in the csv file 'output_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp converter function\n",
    "def TimeStampConverter(inStr, inPat):\n",
    "    timeObj = None\n",
    "    if inStr == \"now\":\n",
    "        timeObj = datetime.now()\n",
    "    else:\n",
    "        timeObj = datetime.strptime(inStr, inPat)\n",
    "    return timeObj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### geting temp., humid. data from influx\n",
    "def fetch_temperature_and_humidity(start_time_str, bucket_remote, url_remote, token_remote, org_remote):\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)\n",
    "    query_api_remote = clientV2_remote.query_api()\n",
    "\n",
    "    start_time = datetime.strptime(str(start_time_str), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    filters = {'_measurement': \"data\"}\n",
    "    query_str = f'from(bucket: \\\"{bucket_remote}\\\") |> range(start: {start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")})'\n",
    "    for k, v in filters.items():\n",
    "        query_str += f' |> filter(fn: (r) => r[\"{k}\"] == \"{v}\")'\n",
    "    query_str += ' |> yield(name: \"mean\")'\n",
    "\n",
    "    query_result_remote = query_api_remote.query_data_frame(org=org_remote, query=query_str)\n",
    "\n",
    "    temperature_results = []\n",
    "    humidity_results = []\n",
    "    for index, row in query_result_remote.iterrows():\n",
    "        if row['_field'] == 'temperature':\n",
    "            temperature_results.append(row.to_dict())\n",
    "        elif row['_field'] == 'humidity':\n",
    "            humidity_results.append(row.to_dict())\n",
    "\n",
    "    if len(temperature_results) > 0:\n",
    "        temperature = temperature_results[0]['_value']\n",
    "    else:\n",
    "        temperature = None\n",
    "\n",
    "    if len(humidity_results) > 0:\n",
    "        humidity = humidity_results[0]['_value']\n",
    "    else:\n",
    "        humidity = None\n",
    "\n",
    "    return temperature, humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform calculations function\n",
    "\n",
    "### useful details\n",
    "\n",
    "def perform_calculations(input_folder, output_file, credentials, timestamp_str):\n",
    "    # Extract credentials\n",
    "    bucket_remote = credentials['bucket']\n",
    "    org_remote = credentials['org']\n",
    "    token_remote = credentials['token']\n",
    "    url_remote = credentials['url']\n",
    "    port = credentials['port']\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    timestamp = TimeStampConverter(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "    \n",
    "     # Initialize the InfluxDB client with the extracted host and port\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, port=int(port), token=token_remote, org=org_remote)\n",
    "\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "            # Calculate Vin Drop and GND Drop\n",
    "            data['Vin Drop (V)'] = data['Vin+ Last (V)'] - data['Vin- Last (V)']\n",
    "            data['GND Drop (V)'] = data['GND+ Last (V)'] - data['GND- Last (V)']\n",
    "            \n",
    "            # Calculate Resistance Vin(Ohms) and Total Resistance(mOhms)\n",
    "            data['Resistance Vin(Ohms)'] = data['Vin Drop (V)'] / 10 / 5\n",
    "            data['Resistance GND(Ohms)'] = data['GND Drop (V)'] / 10 / 5\n",
    "            data['Total Resistance(mOhms)'] = (data['Resistance Vin(Ohms)'] + data['Resistance GND(Ohms)']) * 1000\n",
    "            \n",
    "            # Calculate Capacitor Equivalent leakage current(nA)\n",
    "            data['Capacitor Equivalent leakage current(nA)'] = ((data['Capacitor leakage test Last (V)'] / 10) / (1 * 10 ** 6)) / 1000000\n",
    "            \n",
    "            # Calculate NTC value(Kohms)\n",
    "            data['NTC value (Kohms)'] = 0.2 * 51 / data['NTC Last (V)']\n",
    "            \n",
    "            # Fetch temperature and humidity\n",
    "            temperature, humidity = fetch_temperature_and_humidity(timestamp_str, bucket_remote, url_remote, token_remote, org_remote)\n",
    "            \n",
    "            # Prepare the new DataFrame with desired columns and values\n",
    "            result_data = pd.DataFrame({\n",
    "                'component': filename,\n",
    "                'componentType': 'PCB',\n",
    "                'stage': 'PCB_QC',\n",
    "                'testType': 'HV_LV_TEST',\n",
    "                'institution': 'Glasgow',\n",
    "                'runNumber': data.shape[0],\n",
    "                'date': date.today().strftime('%Y-%m-%d'),\n",
    "                'passed': 'YES',\n",
    "                'problems': 'False',\n",
    "                'property1_value': 'B.masic',\n",
    "                'property1_key': 'OPERATOR',\n",
    "                'property2_value': 'INSTRUMENT',\n",
    "                'property2_key': '',\n",
    "                'property3_value': 'ANALYSIS_VERSION',\n",
    "                'property3_key': '',\n",
    "                'result1_key': 'VIN_DROP',\n",
    "                'result1_value': data['Vin Drop (V)'],\n",
    "                'result2_key': 'GND_DROP',\n",
    "                'result2_value': data['GND Drop (V)'],\n",
    "                'result3_key': 'EFFECTIVE RESISTANCE',\n",
    "                'result3_value': data['Total Resistance(mOhms)'],\n",
    "                'result4_key': 'HV_LEAKAGE',\n",
    "                'result4_value': data['Capacitor leakage test Last (V)'],\n",
    "                'result5_key': 'LEAKAGE_CURRENT (nA)',\n",
    "                'result5_value': data['Capacitor Equivalent leakage current(nA)'],\n",
    "                'result6_key': 'NTC_VOLTAGE',\n",
    "                'result6_value': data['NTC Last (V)'],\n",
    "                'result7_key': 'NTC_VALUE',\n",
    "                'result7_value': data['NTC value (Kohms)'],\n",
    "                'result8_key': 'TERMPERATURE',\n",
    "                'result8_value': temperature,\n",
    "                'result9_key': 'HUMIDITY',\n",
    "                'result9_value': humidity,\n",
    "                'timestamp': [timestamp]  # Add the timestamp column to the DataFrame\n",
    "            })\n",
    "            \n",
    "            all_data.append(result_data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_result = pd.concat(all_data, ignore_index=True)\n",
    "        final_result.to_csv(output_file, index=False)\n",
    "        print(f\"Calculation completed. Output saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Influx info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\client\\warnings.py:31: MissingPivotFunction: The query doesn't contains the pivot() function.\n",
      "\n",
      "The result will not be shaped to optimal processing by pandas.DataFrame. Use the pivot() function by:\n",
      "\n",
      "    from(bucket: \"GLADD\") |> range(start: 2023-08-08T14:30:00Z) |> filter(fn: (r) => r[\"_measurement\"] == \"data\") |> yield(name: \"mean\") |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "\n",
      "You can disable this warning by:\n",
      "    import warnings\n",
      "    from influxdb_client.client.warnings import MissingPivotFunction\n",
      "\n",
      "    warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
      "\n",
      "For more info see:\n",
      "    - https://docs.influxdata.com/resources/videos/pivots-in-flux/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/universe/pivot/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/influxdata/influxdb/schema/fieldsascols/\n",
      "\n",
      "  warnings.warn(message, MissingPivotFunction)\n"
     ]
    },
    {
     "ename": "ApiException",
     "evalue": "(503)\nReason: Service Unavailable\nHTTP response headers: HTTPHeaderDict({'Server': 'squid/4.15', 'Mime-Version': '1.0', 'Date': 'Wed, 09 Aug 2023 13:19:32 GMT', 'Content-Type': 'text/html;charset=utf-8', 'Content-Length': '3984', 'X-Squid-Error': 'ERR_CONNECT_FAIL 111', 'Vary': 'Accept-Language', 'Content-Language': 'en', 'X-Cache': 'MISS from sand, MISS from localhost', 'X-Cache-Lookup': 'MISS from sand:8080, MISS from localhost:3128', 'Via': '1.1 sand (squid/4.15), 1.0 localhost (squid/3.1.19)', 'Connection': 'keep-alive'})\nHTTP response body: b'<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\\n<html><head>\\n<meta type=\"copyright\" content=\"Copyright (C) 1996-2021 The Squid Software Foundation and contributors\">\\n<meta http-equiv=\"Content-Type\" CONTENT=\"text/html; charset=utf-8\">\\n<title>ERROR: The requested URL could not be retrieved</title>\\n<style type=\"text/css\"><!-- \\n /*\\n * Copyright (C) 1996-2021 The Squid Software Foundation and contributors\\n *\\n * Squid software is distributed under GPLv2+ license and includes\\n * contributions from numerous individuals and organizations.\\n * Please see the COPYING and CONTRIBUTORS files for details.\\n */\\n\\n/*\\n Stylesheet for Squid Error pages\\n Adapted from design by Free CSS Templates\\n http://www.freecsstemplates.org\\n Released for free under a Creative Commons Attribution 2.5 License\\n*/\\n\\n/* Page basics */\\n* {\\n\\tfont-family: verdana, sans-serif;\\n}\\n\\nhtml body {\\n\\tmargin: 0;\\n\\tpadding: 0;\\n\\tbackground: #efefef;\\n\\tfont-size: 12px;\\n\\tcolor: #1e1e1e;\\n}\\n\\n/* Page displayed title area */\\n#titles {\\n\\tmargin-left: 15px;\\n\\tpadding: 10px;\\n\\tpadding-left: 100px;\\n\\tbackground: url(\\'/squid-internal-static/icons/SN.png\\') no-repeat left;\\n}\\n\\n/* initial title */\\n#titles h1 {\\n\\tcolor: #000000;\\n}\\n#titles h2 {\\n\\tcolor: #000000;\\n}\\n\\n/* special event: FTP success page titles */\\n#titles ftpsuccess {\\n\\tbackground-color:#00ff00;\\n\\twidth:100%;\\n}\\n\\n/* Page displayed body content area */\\n#content {\\n\\tpadding: 10px;\\n\\tbackground: #ffffff;\\n}\\n\\n/* General text */\\np {\\n}\\n\\n/* error brief description */\\n#error p {\\n}\\n\\n/* some data which may have caused the problem */\\n#data {\\n}\\n\\n/* the error message received from the system or other software */\\n#sysmsg {\\n}\\n\\npre {\\n}\\n\\n/* special event: FTP / Gopher directory listing */\\n#dirmsg {\\n    font-family: courier, monospace;\\n    color: black;\\n    font-size: 10pt;\\n}\\n#dirlisting {\\n    margin-left: 2%;\\n    margin-right: 2%;\\n}\\n#dirlisting tr.entry td.icon,td.filename,td.size,td.date {\\n    border-bottom: groove;\\n}\\n#dirlisting td.size {\\n    width: 50px;\\n    text-align: right;\\n    padding-right: 5px;\\n}\\n\\n/* horizontal lines */\\nhr {\\n\\tmargin: 0;\\n}\\n\\n/* page displayed footer area */\\n#footer {\\n\\tfont-size: 9px;\\n\\tpadding-left: 10px;\\n}\\n\\n\\nbody\\n:lang(fa) { direction: rtl; font-size: 100%; font-family: Tahoma, Roya, sans-serif; float: right; }\\n:lang(he) { direction: rtl; }\\n --></style>\\n</head><body id=ERR_CONNECT_FAIL>\\n<div id=\"titles\">\\n<h1>ERROR</h1>\\n<h2>The requested URL could not be retrieved</h2>\\n</div>\\n<hr>\\n\\n<div id=\"content\">\\n<p>The following error was encountered while trying to retrieve the URL: <a href=\"http://194.36.1.20/api/v2/query?\">http://194.36.1.20/api/v2/query?</a></p>\\n\\n<blockquote id=\"error\">\\n<p><b>Connection to 194.36.1.20 failed.</b></p>\\n</blockquote>\\n\\n<p id=\"sysmsg\">The system returned: <i>(111) Connection refused</i></p>\\n\\n<p>The remote host or network may be down. Please try the request again.</p>\\n\\n<p>Your cache administrator is <a href=\"mailto:root?subject=CacheErrorInfo%20-%20ERR_CONNECT_FAIL&amp;body=CacheHost%3A%20sand%0D%0AErrPage%3A%20ERR_CONNECT_FAIL%0D%0AErr%3A%20(111)%20Connection%20refused%0D%0ATimeStamp%3A%20Wed,%2009%20Aug%202023%2013%3A19%3A32%20GMT%0D%0A%0D%0AClientIP%3A%20130.209.202.202%0D%0AServerIP%3A%20194.36.1.20%0D%0A%0D%0AHTTP%20Request%3A%0D%0APOST%20%2Fapi%2Fv2%2Fquery%3Forg%3DPPE%20HTTP%2F1.1%0AAccept-Encoding%3A%20identity%0D%0AContent-Length%3A%20339%0D%0AAccept%3A%20application%2Fjson%0D%0AContent-Type%3A%20application%2Fjson%0D%0AAuthorization%3A%20Token%20EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ%3D%3D%0D%0AUser-Agent%3A%20influxdb-client-python%2F1.37.0%0D%0AVia%3A%201.1%20localhost%20(squid%2F3.1.19)%0D%0AX-Forwarded-For%3A%2010.120.34.113%0D%0ACache-Control%3A%20max-age%3D259200%0D%0AConnection%3A%20keep-alive%0D%0AHost%3A%20194.36.1.20%0D%0A%0D%0A%0D%0A\">root</a>.</p>\\n\\n<br>\\n</div>\\n\\n<hr>\\n<div id=\"footer\">\\n<p>Generated Wed, 09 Aug 2023 13:19:32 GMT by sand (squid/4.15)</p>\\n<!-- ERR_CONNECT_FAIL -->\\n</div>\\n</body></html>\\n'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7932\\1846989558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0minflux_credentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetInfluxCredentials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mperform_calculations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minflux_credentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7932\\489335865.py\u001b[0m in \u001b[0;36mperform_calculations\u001b[1;34m(input_folder, output_file, credentials, timestamp_str)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Fetch temperature and humidity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhumidity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_temperature_and_humidity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamp_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket_remote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_remote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_remote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morg_remote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Prepare the new DataFrame with desired columns and values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7932\\964807286.py\u001b[0m in \u001b[0;36mfetch_temperature_and_humidity\u001b[1;34m(start_time_str, bucket_remote, url_remote, token_remote, org_remote)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mquery_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' |> yield(name: \"mean\")'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mquery_result_remote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_api_remote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morg_remote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtemperature_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\client\\query_api.py\u001b[0m in \u001b[0;36mquery_data_frame\u001b[1;34m(self, query, org, data_frame_index, params)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;33m-\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfluxdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mflux\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mstdlib\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0minfluxdata\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0minfluxdb\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfieldsascols\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \"\"\"  # noqa: E501\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0m_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_data_frame_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_frame_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_frame_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_data_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\client\\query_api.py\u001b[0m in \u001b[0;36mquery_data_frame_stream\u001b[1;34m(self, query, org, data_frame_index, params)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0morg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_org_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         response = self._query_api.post_query(org=org, query=self._create_query(query, self.default_dialect, params,\n\u001b[0m\u001b[0;32m    287\u001b[0m                                                                                 dataframe_query=True),\n\u001b[0;32m    288\u001b[0m                                               async_req=False, _preload_content=False, _return_http_data_only=False)\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\service\\query_service.py\u001b[0m in \u001b[0;36mpost_query\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_query_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_query_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\service\\query_service.py\u001b[0m in \u001b[0;36mpost_query_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_query_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         return self.api_client.call_api(\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;34m'/api/v2/query'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mpath_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\_sync\\api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, urlopen_kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \"\"\"\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[0;32m    344\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\_sync\\api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, urlopen_kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# perform request and return response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         response_data = self.request(\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mpost_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\_sync\\api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[0;32m    386\u001b[0m                                             **urlopen_kw)\n\u001b[0;32m    387\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             return self.rest_client.POST(url,\n\u001b[0m\u001b[0;32m    389\u001b[0m                                          \u001b[0mquery_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                                          \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\_sync\\rest.py\u001b[0m in \u001b[0;36mPOST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[0;32m    309\u001b[0m              body=None, _preload_content=True, _request_timeout=None, **urlopen_kw):\n\u001b[0;32m    310\u001b[0m         \u001b[1;34m\"\"\"Perform POST HTTP request.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         return self.request(\"POST\", url,\n\u001b[0m\u001b[0;32m    312\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\_sync\\rest.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mApiException\u001b[0m: (503)\nReason: Service Unavailable\nHTTP response headers: HTTPHeaderDict({'Server': 'squid/4.15', 'Mime-Version': '1.0', 'Date': 'Wed, 09 Aug 2023 13:19:32 GMT', 'Content-Type': 'text/html;charset=utf-8', 'Content-Length': '3984', 'X-Squid-Error': 'ERR_CONNECT_FAIL 111', 'Vary': 'Accept-Language', 'Content-Language': 'en', 'X-Cache': 'MISS from sand, MISS from localhost', 'X-Cache-Lookup': 'MISS from sand:8080, MISS from localhost:3128', 'Via': '1.1 sand (squid/4.15), 1.0 localhost (squid/3.1.19)', 'Connection': 'keep-alive'})\nHTTP response body: b'<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\\n<html><head>\\n<meta type=\"copyright\" content=\"Copyright (C) 1996-2021 The Squid Software Foundation and contributors\">\\n<meta http-equiv=\"Content-Type\" CONTENT=\"text/html; charset=utf-8\">\\n<title>ERROR: The requested URL could not be retrieved</title>\\n<style type=\"text/css\"><!-- \\n /*\\n * Copyright (C) 1996-2021 The Squid Software Foundation and contributors\\n *\\n * Squid software is distributed under GPLv2+ license and includes\\n * contributions from numerous individuals and organizations.\\n * Please see the COPYING and CONTRIBUTORS files for details.\\n */\\n\\n/*\\n Stylesheet for Squid Error pages\\n Adapted from design by Free CSS Templates\\n http://www.freecsstemplates.org\\n Released for free under a Creative Commons Attribution 2.5 License\\n*/\\n\\n/* Page basics */\\n* {\\n\\tfont-family: verdana, sans-serif;\\n}\\n\\nhtml body {\\n\\tmargin: 0;\\n\\tpadding: 0;\\n\\tbackground: #efefef;\\n\\tfont-size: 12px;\\n\\tcolor: #1e1e1e;\\n}\\n\\n/* Page displayed title area */\\n#titles {\\n\\tmargin-left: 15px;\\n\\tpadding: 10px;\\n\\tpadding-left: 100px;\\n\\tbackground: url(\\'/squid-internal-static/icons/SN.png\\') no-repeat left;\\n}\\n\\n/* initial title */\\n#titles h1 {\\n\\tcolor: #000000;\\n}\\n#titles h2 {\\n\\tcolor: #000000;\\n}\\n\\n/* special event: FTP success page titles */\\n#titles ftpsuccess {\\n\\tbackground-color:#00ff00;\\n\\twidth:100%;\\n}\\n\\n/* Page displayed body content area */\\n#content {\\n\\tpadding: 10px;\\n\\tbackground: #ffffff;\\n}\\n\\n/* General text */\\np {\\n}\\n\\n/* error brief description */\\n#error p {\\n}\\n\\n/* some data which may have caused the problem */\\n#data {\\n}\\n\\n/* the error message received from the system or other software */\\n#sysmsg {\\n}\\n\\npre {\\n}\\n\\n/* special event: FTP / Gopher directory listing */\\n#dirmsg {\\n    font-family: courier, monospace;\\n    color: black;\\n    font-size: 10pt;\\n}\\n#dirlisting {\\n    margin-left: 2%;\\n    margin-right: 2%;\\n}\\n#dirlisting tr.entry td.icon,td.filename,td.size,td.date {\\n    border-bottom: groove;\\n}\\n#dirlisting td.size {\\n    width: 50px;\\n    text-align: right;\\n    padding-right: 5px;\\n}\\n\\n/* horizontal lines */\\nhr {\\n\\tmargin: 0;\\n}\\n\\n/* page displayed footer area */\\n#footer {\\n\\tfont-size: 9px;\\n\\tpadding-left: 10px;\\n}\\n\\n\\nbody\\n:lang(fa) { direction: rtl; font-size: 100%; font-family: Tahoma, Roya, sans-serif; float: right; }\\n:lang(he) { direction: rtl; }\\n --></style>\\n</head><body id=ERR_CONNECT_FAIL>\\n<div id=\"titles\">\\n<h1>ERROR</h1>\\n<h2>The requested URL could not be retrieved</h2>\\n</div>\\n<hr>\\n\\n<div id=\"content\">\\n<p>The following error was encountered while trying to retrieve the URL: <a href=\"http://194.36.1.20/api/v2/query?\">http://194.36.1.20/api/v2/query?</a></p>\\n\\n<blockquote id=\"error\">\\n<p><b>Connection to 194.36.1.20 failed.</b></p>\\n</blockquote>\\n\\n<p id=\"sysmsg\">The system returned: <i>(111) Connection refused</i></p>\\n\\n<p>The remote host or network may be down. Please try the request again.</p>\\n\\n<p>Your cache administrator is <a href=\"mailto:root?subject=CacheErrorInfo%20-%20ERR_CONNECT_FAIL&amp;body=CacheHost%3A%20sand%0D%0AErrPage%3A%20ERR_CONNECT_FAIL%0D%0AErr%3A%20(111)%20Connection%20refused%0D%0ATimeStamp%3A%20Wed,%2009%20Aug%202023%2013%3A19%3A32%20GMT%0D%0A%0D%0AClientIP%3A%20130.209.202.202%0D%0AServerIP%3A%20194.36.1.20%0D%0A%0D%0AHTTP%20Request%3A%0D%0APOST%20%2Fapi%2Fv2%2Fquery%3Forg%3DPPE%20HTTP%2F1.1%0AAccept-Encoding%3A%20identity%0D%0AContent-Length%3A%20339%0D%0AAccept%3A%20application%2Fjson%0D%0AContent-Type%3A%20application%2Fjson%0D%0AAuthorization%3A%20Token%20EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ%3D%3D%0D%0AUser-Agent%3A%20influxdb-client-python%2F1.37.0%0D%0AVia%3A%201.1%20localhost%20(squid%2F3.1.19)%0D%0AX-Forwarded-For%3A%2010.120.34.113%0D%0ACache-Control%3A%20max-age%3D259200%0D%0AConnection%3A%20keep-alive%0D%0AHost%3A%20194.36.1.20%0D%0A%0D%0A%0D%0A\">root</a>.</p>\\n\\n<br>\\n</div>\\n\\n<hr>\\n<div id=\"footer\">\\n<p>Generated Wed, 09 Aug 2023 13:19:32 GMT by sand (squid/4.15)</p>\\n<!-- ERR_CONNECT_FAIL -->\\n</div>\\n</body></html>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Run calculations\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = os.path.join(parentDir, \"picolog_folder\")\n",
    "    output_file = os.path.join(parentDir, \"output_file.csv\")\n",
    "    timestamp_str = \"2023-08-08 14:30:00\"\n",
    "    \n",
    "    influx_credentials = GetInfluxCredentials()\n",
    "    \n",
    "    perform_calculations(input_folder, output_file, influx_credentials, timestamp_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
