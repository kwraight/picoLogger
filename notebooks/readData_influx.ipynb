{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.exceptions import InfluxDBError\n",
    "from getpass import getpass\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from connectionDetails_template import GetInfluxCredentials  # Import the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set influx connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas : 1.4.4\n",
      "altair : 5.0.1\n",
      "numpy : 1.21.5\n",
      "itkdb not installed\n",
      "Files in parent directory: ['.git', '.gitignore', '.ipynb_checkpoints', 'notebooks', 'output_file.csv', 'picolog_folder', 'README.md', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "# List installed package versions\n",
    "packList = [\"pandas\", \"altair\", \"numpy\", \"itkdb\"]\n",
    "for p in packList:\n",
    "    try:\n",
    "        mod = __import__(p)\n",
    "        print(mod.__name__ + \" : \" + mod.__version__)\n",
    "    except ImportError:\n",
    "        print(p + \" not installed\")\n",
    "\n",
    "# Get the current working directory\n",
    "thisDir = os.getcwd()\n",
    "\n",
    "# List files in the parent directory\n",
    "parentDir = os.path.abspath(os.path.join(thisDir, os.pardir))\n",
    "files_in_parent = os.listdir(parentDir)\n",
    "print(\"Files in parent directory:\", files_in_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data\n",
    "\n",
    "The code below takes in the flux data as well as the data from the picolog folder to perform calculations on them and produce an output in the csv file 'output_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp converter function\n",
    "def TimeStampConverter(inStr, inPat):\n",
    "    timeObj = None\n",
    "    if inStr == \"now\":\n",
    "        timeObj = datetime.now()\n",
    "    else:\n",
    "        timeObj = datetime.strptime(inStr, inPat)\n",
    "    return timeObj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### geting temp., humid. data from influx\n",
    "def fetch_temperature_and_humidity(start_time_str, bucket_remote, url_remote, token_remote, org_remote):\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)\n",
    "    query_api_remote = clientV2_remote.query_api()\n",
    "\n",
    "    start_time = datetime.strptime(str(start_time_str), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    filters = {'_measurement': \"data\"}\n",
    "    query_str = f'from(bucket: \\\"{bucket_remote}\\\") |> range(start: {start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")})'\n",
    "    for k, v in filters.items():\n",
    "        query_str += f' |> filter(fn: (r) => r[\"{k}\"] == \"{v}\")'\n",
    "    query_str += ' |> yield(name: \"mean\")'\n",
    "\n",
    "    try:\n",
    "        query_result_remote = query_api_remote.query_data_frame(org=org_remote, query=query_str)\n",
    "\n",
    "        temperature_results = []\n",
    "        humidity_results = []\n",
    "        for index, row in query_result_remote.iterrows():\n",
    "            if row['_field'] == 'temperature':\n",
    "                temperature_results.append(row.to_dict())\n",
    "            elif row['_field'] == 'humidity':\n",
    "                humidity_results.append(row.to_dict())\n",
    "\n",
    "        if len(temperature_results) > 0:\n",
    "            temperature = temperature_results[0]['_value']\n",
    "        else:\n",
    "            temperature = None\n",
    "\n",
    "        if len(humidity_results) > 0:\n",
    "            humidity = humidity_results[0]['_value']\n",
    "        else:\n",
    "            humidity = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"issue with query:\")\n",
    "        print(e)\n",
    "        temperature, humidity = None, None\n",
    "\n",
    "    return temperature, humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform calculations function\n",
    "\n",
    "### useful details\n",
    "\n",
    "def perform_calculations(input_folder, output_file, credentials, timestamp_str):\n",
    "    # Extract credentials\n",
    "    bucket_remote = credentials['bucket']\n",
    "    org_remote = credentials['org']\n",
    "    token_remote = credentials['token']\n",
    "    url_remote = credentials['url']\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    timestamp = TimeStampConverter(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "    \n",
    "     # Initialize the InfluxDB client with the extracted host and port\n",
    "    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)\n",
    "\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "            # Calculate Vin Drop and GND Drop\n",
    "            data['Vin Drop (V)'] = data['Vin+ Last (V)'] - data['Vin- Last (V)']\n",
    "            data['GND Drop (V)'] = data['GND+ Last (V)'] - data['GND- Last (V)']\n",
    "            \n",
    "            # Calculate Resistance Vin(Ohms) and Total Resistance(mOhms)\n",
    "            data['Resistance Vin(Ohms)'] = data['Vin Drop (V)'] / 10 / 5\n",
    "            data['Resistance GND(Ohms)'] = data['GND Drop (V)'] / 10 / 5\n",
    "            data['Total Resistance(mOhms)'] = (data['Resistance Vin(Ohms)'] + data['Resistance GND(Ohms)']) * 1000\n",
    "            \n",
    "            # Calculate Capacitor Equivalent leakage current(nA)\n",
    "            data['Capacitor Equivalent leakage current(nA)'] = ((data['Capacitor leakage test Last (V)'] / 10) / (1 * 10 ** 6)) / 1000000\n",
    "            \n",
    "            # Calculate NTC value(Kohms)\n",
    "            data['NTC value (Kohms)'] = 0.2 * 51 / data['NTC Last (V)']\n",
    "            \n",
    "            # Fetch temperature and humidity\n",
    "            temperature, humidity = fetch_temperature_and_humidity(timestamp_str, bucket_remote, url_remote, token_remote, org_remote)\n",
    "            \n",
    "            # Prepare the new DataFrame with desired columns and values\n",
    "            result_data = pd.DataFrame({\n",
    "                'component': filename,\n",
    "                'componentType': 'PCB',\n",
    "                'stage': 'PCB_QC',\n",
    "                'testType': 'HV_LV_TEST',\n",
    "                'institution': 'Glasgow',\n",
    "                'runNumber': data.shape[0],\n",
    "                'date': date.today().strftime('%Y-%m-%d'),\n",
    "                'passed': 'true',\n",
    "                'problems': 'false',\n",
    "                'property1_value': 'B.masic',\n",
    "                'property1_key': 'OPERATOR',\n",
    "                'property2_value': 'INSTRUMENT',\n",
    "                'property2_key': '',\n",
    "                'property3_value': 'ANALYSIS_VERSION',\n",
    "                'property3_key': '',\n",
    "                'result1_key': 'VIN_DROP',\n",
    "                'result1_value': data['Vin Drop (V)'],\n",
    "                'result2_key': 'GND_DROP',\n",
    "                'result2_value': data['GND Drop (V)'],\n",
    "                'result3_key': 'EFFECTIVE RESISTANCE',\n",
    "                'result3_value': data['Total Resistance(mOhms)'],\n",
    "                'result4_key': 'HV_LEAKAGE',\n",
    "                'result4_value': data['Capacitor leakage test Last (V)'],\n",
    "                'result5_key': 'LEAKAGE_CURRENT (nA)',\n",
    "                'result5_value': data['Capacitor Equivalent leakage current(nA)'],\n",
    "                'result6_key': 'NTC_VOLTAGE',\n",
    "                'result6_value': data['NTC Last (V)'],\n",
    "                'result7_key': 'NTC_VALUE',\n",
    "                'result7_value': data['NTC value (Kohms)'],\n",
    "                'result8_key': 'TERMPERATURE',\n",
    "                'result8_value': temperature,\n",
    "                'result9_key': 'DAMAGE_COMMENT',\n",
    "                'result9_value': '',\n",
    "                'result10_key': 'R1_HV_RESISTOR',\n",
    "                'result10_value': '',\n",
    "                'result11_key': 'RELATIVE_HUMIDITY',\n",
    "                'result11_value': humidity,\n",
    "                'timestamp': [timestamp]  # Add the timestamp column to the DataFrame\n",
    "            })\n",
    "            \n",
    "            all_data.append(result_data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_result = pd.concat(all_data, ignore_index=True)\n",
    "        final_result.to_csv(output_file, index=False)\n",
    "        print(f\"Calculation completed. Output saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Influx info.\n",
      "{'bucket': 'BUCKET', 'org': 'ORG', 'token': 'TOKEN', 'url': 'URL:PORT'}\n",
      "issue with query:\n",
      "No host specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\New folder\\lib\\site-packages\\influxdb_client\\client\\warnings.py:31: MissingPivotFunction: The query doesn't contains the pivot() function.\n",
      "\n",
      "The result will not be shaped to optimal processing by pandas.DataFrame. Use the pivot() function by:\n",
      "\n",
      "    from(bucket: \"BUCKET\") |> range(start: 2023-08-08T14:30:00Z) |> filter(fn: (r) => r[\"_measurement\"] == \"data\") |> yield(name: \"mean\") |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "\n",
      "You can disable this warning by:\n",
      "    import warnings\n",
      "    from influxdb_client.client.warnings import MissingPivotFunction\n",
      "\n",
      "    warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
      "\n",
      "For more info see:\n",
      "    - https://docs.influxdata.com/resources/videos/pivots-in-flux/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/universe/pivot/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/influxdata/influxdb/schema/fieldsascols/\n",
      "\n",
      "  warnings.warn(message, MissingPivotFunction)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 1 does not match index length 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9372\\2708554779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minflux_credentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mperform_calculations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minflux_credentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9372\\2034324741.py\u001b[0m in \u001b[0;36mperform_calculations\u001b[1;34m(input_folder, output_file, credentials, timestamp_str)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# Prepare the new DataFrame with desired columns and values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             result_data = pd.DataFrame({\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[1;34m'component'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;34m'componentType'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'PCB'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    686\u001b[0m                         \u001b[1;34mf\"length {len(index)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                     )\n\u001b[1;32m--> 688\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array length 1 does not match index length 3"
     ]
    }
   ],
   "source": [
    "# Run calculations\n",
    "input_folder = os.path.join(parentDir, \"picolog_folder\")\n",
    "output_file = os.path.join(parentDir, \"output_file.csv\")\n",
    "timestamp_str = \"2023-08-08 14:30:00\"\n",
    "\n",
    "influx_credentials = GetInfluxCredentials()\n",
    "print(influx_credentials)\n",
    "\n",
    "perform_calculations(input_folder, output_file, influx_credentials, timestamp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
