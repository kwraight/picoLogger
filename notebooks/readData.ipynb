{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to read the files, we need to import certain modules. Pandas and altair allow us to plot the data in the picologger file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import datetime,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas : 1.4.4\n",
      "altair : 5.0.1\n",
      "numpy : 1.21.5\n",
      "itkdb not installed\n",
      "Files in parent directory: ['.git', '.gitignore', '.ipynb_checkpoints', 'notebooks', 'output_file.csv', 'picolog_folder', 'README.md', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "# List installed package versions\n",
    "packList = [\"pandas\", \"altair\", \"numpy\", \"itkdb\"]\n",
    "for p in packList:\n",
    "    try:\n",
    "        mod = __import__(p)\n",
    "        print(mod.__name__ + \" : \" + mod.__version__)\n",
    "    except ImportError:\n",
    "        print(p + \" not installed\")\n",
    "\n",
    "# Get the current working directory\n",
    "thisDir = os.getcwd()\n",
    "\n",
    "# List files in the parent directory\n",
    "parentDir = os.path.abspath(os.path.join(thisDir, os.pardir))\n",
    "files_in_parent = os.listdir(parentDir)\n",
    "print(\"Files in parent directory:\", files_in_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'notebooks',\n",
       " 'output_file.csv',\n",
       " 'picolog_folder',\n",
       " 'README.md',\n",
       " 'requirements.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### list files in above directory\n",
    "thisDir = os.getcwd()\n",
    "os.listdir(thisDir+\"/../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection details:\n",
      "bucket_remote: GLADD\n",
      "org_remote: PPE\n",
      "token_remote: EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ==\n",
      "url_remote: 194.36.1.20:8086\n"
     ]
    }
   ],
   "source": [
    "# Original credentials\n",
    "bucket_remote = \"GLADD\"\n",
    "org_remote = \"PPE\"\n",
    "token_remote = \"EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ==\"\n",
    "url_remote = \"194.36.1.20:8086\"\n",
    "\n",
    "print(\"Connection details:\")\n",
    "print(f\"bucket_remote: {bucket_remote}\")\n",
    "print(f\"org_remote: {org_remote}\")\n",
    "print(f\"token_remote: {token_remote}\")\n",
    "print(f\"url_remote: {url_remote}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format raw data\n",
    "The following data takes in all of the files from the picologger folder,performs necessary calculations on them and puts them all in one csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp converter function\n",
    "def TimeStampConverter(inStr, inPat):\n",
    "    timeObj = None\n",
    "    if inStr == \"now\":\n",
    "        timeObj = datetime.now()\n",
    "    else:\n",
    "        timeObj = datetime.strptime(inStr, inPat)\n",
    "    return timeObj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### derive values from picoLogger raw data\n",
    "# Perform calculations function\n",
    "def perform_calculations(input_folder, output_file, url_remote, token_remote, org_remote, timestamp_str):\n",
    "    all_data = []\n",
    "\n",
    "    timestamp = TimeStampConverter(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            \n",
    "            # Calculate Vin Drop and GND Drop\n",
    "            data['Vin Drop (V)'] = data['Vin+ Last (V)'] - data['Vin- Last (V)']\n",
    "            data['GND Drop (V)'] = data['GND+ Last (V)'] - data['GND- Last (V)']\n",
    "            \n",
    "            # Calculate Resistance Vin(Ohms) and Total Resistance(mOhms)\n",
    "            data['Resistance Vin(Ohms)'] = data['Vin Drop (V)'] / 10 / 5\n",
    "            data['Resistance GND(Ohms)'] = data['GND Drop (V)'] / 10 / 5\n",
    "            data['Total Resistance(mOhms)'] = (data['Resistance Vin(Ohms)'] + data['Resistance GND(Ohms)']) * 1000\n",
    "            \n",
    "            # Calculate Capacitor Equivalent leakage current(nA)\n",
    "            data['Capacitor Equivalent leakage current(nA)'] = ((data['Capacitor leakage test Last (V)'] / 10) / (1 * 10 ** 6)) / 1000000\n",
    "            \n",
    "            # Calculate NTC value(Kohms)\n",
    "            data['NTC value (Kohms)'] = 0.2 * 51 / data['NTC Last (V)']\n",
    "                        \n",
    "            # Prepare the new DataFrame with desired columns and values\n",
    "            result_data = pd.DataFrame({\n",
    "                'component': filename,\n",
    "                'componentType': 'PCB',\n",
    "                'stage': 'PCB_QC',\n",
    "                'testType': 'HV_LV_TEST',\n",
    "                'institution': 'Glasgow',\n",
    "                'runNumber': data.shape[0],\n",
    "                'date': date.today().strftime('%Y-%m-%d'),\n",
    "                'passed': 'YES',\n",
    "                'problems': 'False',\n",
    "                'property1_value': 'B.masic',\n",
    "                'property1_key': 'OPERATOR',\n",
    "                'property2_value': 'INSTRUMENT',\n",
    "                'property2_key': '',\n",
    "                'property3_value': 'ANALYSIS_VERSION',\n",
    "                'property3_key': '',\n",
    "                'result1_key': 'VIN_DROP',\n",
    "                'result1_value': data['Vin Drop (V)'],\n",
    "                'result2_key': 'GND_DROP',\n",
    "                'result2_value': data['GND Drop (V)'],\n",
    "                'result3_key': 'EFFECTIVE RESISTANCE',\n",
    "                'result3_value': data['Total Resistance(mOhms)'],\n",
    "                'result4_key': 'HV_LEAKAGE',\n",
    "                'result4_value': data['Capacitor leakage test Last (V)'],\n",
    "                'result5_key': 'LEAKAGE_CURRENT (nA)',\n",
    "                'result5_value': data['Capacitor Equivalent leakage current(nA)'],\n",
    "                'result6_key': 'NTC_VOLTAGE',\n",
    "                'result6_value': data['NTC Last (V)'],\n",
    "                'result7_key': 'NTC_VALUE',\n",
    "                'result7_value': data['NTC value (Kohms)']\n",
    "            })\n",
    "            \n",
    "            all_data.append(result_data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_result = pd.concat(all_data, ignore_index=True)\n",
    "        final_result.to_csv(output_file, index=False)\n",
    "        print(f\"Calculation completed. Output saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed. Output saved to C:\\Users\\User\\Documents\\GitHub\\picoLogger\\notebooks/../output_file.csv.\n"
     ]
    }
   ],
   "source": [
    "### run conversion\n",
    "input_folder = thisDir+\"/../picolog_folder/\"\n",
    "output_file = thisDir+\"/../output_file.csv\"\n",
    "timestamp_str = \"2023-08-08 14:30:00\"  # Replace this with your desired timestamp\n",
    "\n",
    "perform_calculations(input_folder, output_file, url_remote, token_remote, org_remote, timestamp_str)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
